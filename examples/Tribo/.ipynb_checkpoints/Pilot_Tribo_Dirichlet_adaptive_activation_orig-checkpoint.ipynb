{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File von Maren 11.04.2022\n",
    "# Spaltfunktion h(x)=g(x)+delta(x)\n",
    "# Integral für Dehnung ist eingebaut - delta wieder deaktiviert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchphysics as tp\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from IPython.display import display, Math, Latex\n",
    "import time\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Training on', device)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide to train a new model or to load an existing one\n",
    "train_new = True\n",
    "#trained_model_name = '.pt'\n",
    "trained_model_name = 'Trained_Model_Tribo.pt'\n",
    "new_trained_model_name = 'Trained_Model_Tribo_new.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Tutorial zu TorchPhysics:')\n",
    "#print('https://torchphysics.readthedocs.io/en/latest/tutorial/tutorial_start.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display('Reynoldsgleichung (1.1) aus Multilevel Methods in Lubrication von C.H. Venner and A.A. Lubrecht')\n",
    "#display(Math(r'u_m \\frac{d}{d x} ( \\rho h) - \\frac{d}{ dx} \\left( \\frac{\\rho h^3}{12 \\nu} \\\n",
    "#   \\frac{d}{d x} \\right) = 0 \\quad \\mbox{with} \\quad \\rho=\\rho(p)\\,, \\quad \\nu=\\nu(p)\\,, \\quad h=h(x) '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konstanten für Stoffunktionen\n",
    "beta = 2.2*1e-08 \t# 2.2e-08 m^2/N\n",
    "nu_0 = 15e-03 \t\t# Pa·s = 1.5 mPa·s\n",
    "# lower and upper bounds of parameters\n",
    "# Viskosität [Pa s]\n",
    "\n",
    "\n",
    "rho_0 = 800\n",
    "\n",
    "# Geschwindigkeit [m/s]\n",
    "\n",
    "um_0 = 2.0\n",
    "# Abstand von Kugel-Platte [m]\n",
    "\n",
    "#dh_0 = -1.51932e-6\n",
    "dh_0 = 0.2e-6\n",
    "\n",
    "pskal = 1e+7\n",
    "# ------------------------------------------------\n",
    "# Konstanten von Sergey\n",
    "FN = 170000 # N hier ist Einheit wichtig!!\n",
    "R = 0.0027 # m\n",
    "E1 = 210*1e+9 # N/m2\n",
    "v1 =0.3 \n",
    "\n",
    "Er = E1/(1-v1*v1)\n",
    "\n",
    "# Integrationsintervallgrenze\n",
    "#IG = 35*np.sqrt((8*R*FN)/(Er*np.pi))\n",
    "a = np.sqrt((8*R*FN)/(Er*np.pi))\n",
    "\n",
    "lamb = pskal*a**3/(12*nu_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define g_tilde: x/a, but also g/a**2\n",
    "def g(x, dh):   \n",
    "    \n",
    "    out = dh/(a**2) + x**2/(2*R)\n",
    "    return out\n",
    "\n",
    "def g_x(x, dh):\n",
    "    \n",
    "    out = x/R\n",
    "  \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define delta\n",
    "# Verformung nach einem einfachen Mechanikgesetz\n",
    "\n",
    "eps=1e-16\n",
    "\n",
    "def delta(p_integral, x, x_integral):\n",
    "    #Version mit oder ohne Skalierung durch a - Unterschied Verschiebung um Konstante\n",
    "    #out = -4/(np.pi*Er)*6*a*torch.mean(pskal*p_integral*torch.log((torch.abs(x-x_integral)/a+eps)), dim=1)\n",
    "    #out = -4/(np.pi*Er)*6*a*torch.mean(pskal*p_integral*torch.log(torch.abs(x-x_integral)+eps), dim=1)\n",
    "    out = torch.zeros_like(x)\n",
    "    return out\n",
    "\n",
    "def delta_x(p_integral, x, x_integral):   \n",
    "    #out = -4/(np.pi*Er)*6*a*torch.mean(pskal*p_integral/(torch.abs(x-x_integral)+eps)*torch.sgn(x-x_integral), dim=1)  \n",
    "    out = torch.zeros_like(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalthoehe entspricht h = g + delta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rho_tilde: rho/rho0\n",
    "def rho_func(p):\n",
    "    A = 5.9e+8\n",
    "    B = 1.34   \n",
    "    \n",
    "    return (A+B*p*pskal)/(A+p*pskal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rho_p\n",
    "#rho_tilde: rho/rho0\n",
    "def rho_p_func(p):\n",
    "    A = 5.9e+8\n",
    "    B = 1.34\n",
    "    \n",
    "    return ((B/(A+p*pskal)- (A+B*p*pskal)/((A+p*pskal)*(A+p*pskal))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viskosität\n",
    "# eta_tilde = eta/eta_0\n",
    "def eta_func(p):\n",
    "    out = torch.exp(beta * p*pskal)\n",
    "    return torch.clamp(out, min=1e-06)\n",
    "\n",
    "\n",
    "def eta_p_func(p): # Ableitung der Viskosität nach dem Druck p\n",
    "    out = beta*torch.exp(beta*p*pskal)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_p(p):\n",
    "    #out = torch.nn.functional.relu(-p)*p**2\n",
    "    pen_fac = 1e7\n",
    "    out = pen_fac * torch.nn.functional.relu(-p)\n",
    "    #out = p*pskal * torch.nn.functional.relu(-p)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables:\n",
    "x  = tp.spaces.R1('x')\n",
    "\n",
    "# output\n",
    "p = tp.spaces.R1('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A_x  = tp.domains.Interval(x, -4*a, 2*a)\n",
    "A_x  = tp.domains.Interval(x, -4, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_sampler = tp.samplers.RandomUniformSampler(A_x, n_points = 15000) \n",
    "\n",
    "#inner_sampler = tp.samplers.AdaptiveRejectionSampler(A_x,n_points = 1000)\n",
    "\n",
    "#integral_sampler = tp.samplers.RandomUniformSampler(A_x, n_points=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp.utils.scatter(nu*um*dh, inner_sampler, boundary_v_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from activation_fn import AdaptiveActivationFunction\n",
    "#model_path = 'Pilot1.pt'\n",
    "a_fn = AdaptiveActivationFunction(torch.nn.Tanh())\n",
    "model = tp.models.Sequential(\n",
    "    tp.models.NormalizationLayer(A_x),\n",
    "    tp.models.QRES(input_space=x, output_space=p,hidden=(30,30,30,30), \n",
    "                  activations=a_fn))#(50,50,50,50)))#,50,50,50,50)))\n",
    "#if os.path.exists(model_path):\n",
    "#    model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(Math(r'h(x)\\frac{d^2 \\tilde{p}}{d x^2}  +\\left( 3 \\frac{dh}{dx} - \\frac{h}{\\nu} \\frac{d \\nu}{d x} \\\n",
    "#    \\right) \\frac{d \\tilde{p}}{d x} = \\frac{6 u_m \\nu}{p_0 h^2} \\frac{d h}{d x}\\quad \\mbox{with} \\\n",
    "#    \\quad \\tilde{p}=\\frac{p}{p_{skal}} '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz_func(x,p):    \n",
    "    #return torch.where(x >-1, (2-x)*p, (x+4)*p) \n",
    "    #return \n",
    "    #return p\n",
    "    return (2-x)*(x+4)*p/10.0\n",
    "    #return (2-x)*(x+4)*torch.exp(-(x*a)**2)*p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchphysics.utils import grad\n",
    "from torchphysics.utils import laplacian\n",
    "\n",
    "def pde(p,  x): \n",
    "#def pde(p, p_integral, x, x_integral):     \n",
    "   \n",
    "   \n",
    "    q=ansatz_func(x,p)\n",
    "    \n",
    "    #q_integral = ansatz_func(x_integral,p_integral)\n",
    "    \n",
    "    # evaluate the viscosity and their first derivative\n",
    "    eta = eta_func(q)\n",
    "    eta_p = eta_p_func(q) \n",
    "    # implement the PDE:  \n",
    "    #  g und g_x mit Input dh:\n",
    "    g_out = g(x, dh_0) # nur einmal auswerten\n",
    "    g_x_out = g_x(x, dh_0) # nur einmal auswerten\n",
    "    # delta und delta_p bereitstellen\n",
    "    #delta_out = delta(q_integral, x, x_integral) # s.o.\n",
    "    #delta_x_out = delta_x(q_integral, x, x_integral)\n",
    "    \n",
    "    h_out = g_out# + delta_out\n",
    "    h_x_out = g_x_out# + delta_x_out\n",
    "    # Dichtegradient bereitstellen\n",
    "    rho_out = rho_func(q)\n",
    "    rho_p_out = rho_p_func(q)\n",
    "    \n",
    "    s1 = -lamb\n",
    "    s2 = um_0*pskal*h_out*rho_p_out - 3*lamb*h_out**2/(eta)*rho_out*h_x_out \n",
    "    s3 = lamb*(h_out**3)/eta*(eta_p*rho_out/eta - rho_p_out) \n",
    "    s4 = um_0*rho_out*h_x_out\n",
    "    #print(s2)\n",
    "   \n",
    "    out =s1*grad(grad(q,x),x) + s2*grad(q,x) + s3*grad(q,x)**2 + s4\n",
    "    return 1e-5*out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_residual(p):\n",
    "    return torch.clamp(p, max=0)\n",
    "\n",
    "pos_sampler = tp.samplers.RandomUniformSampler(A_x, n_points = 3000) \n",
    "\n",
    "pos_condition = tp.conditions.PINNCondition(module=model,\n",
    "                                            sampler=pos_sampler,\n",
    "                                            residual_fn=positive_residual,   \n",
    "                                            weight=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde_condition = tp.conditions.PINNCondition(module=model,\n",
    "                                                   sampler=inner_sampler,\n",
    "                                                   residual_fn=pde,   \n",
    "                                                   weight=1000,\n",
    "                                                   #integral_sampler=integral_sampler,\n",
    "                                                   name='pde_condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training des Modells oder laden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-GPU-9bdc43ab-3c7a-9d92-3ec5-4207d76cdb68/13/0]\n",
      "\n",
      "  | Name             | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | train_conditions | ModuleList | 5.6 K \n",
      "1 | val_conditions   | ModuleList | 0     \n",
      "------------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n",
      "/home/krd2rng/.conda/envs/pytorch-physics/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/krd2rng/.conda/envs/pytorch-physics/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f4ce0117084bd0b514a115c9c2b974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if train_new:\n",
    "    # zu LBFGS wechseln. \n",
    "    # hier LBFGS setzen\n",
    "   #optim = tp.OptimizerSetting(optimizer_class=torch.optim.LBFGS, lr=0.1, \n",
    "     #                       optimizer_args={'max_iter': 2, 'history_size': 100})\n",
    "    #optim = tp.solver.OptimizerSetting(torch.optim.Adam, lr=1e-5) #SGD, LBFGS\n",
    "    optim = tp.solver.OptimizerSetting(torch.optim.Adam, lr=1e-3) #SGD, LBFGS\n",
    "    solver = tp.solver.Solver([pde_condition, pos_condition],optimizer_setting = optim)\n",
    "    #solver = tp.solver.Solver((pde_condition, boundary_condition),optimizer_setting = optim)\n",
    "\n",
    "    trainer = pl.Trainer(gpus='-1' if torch.cuda.is_available() else None,\n",
    "                     num_sanity_val_steps=0,\n",
    "                     benchmark=True,\n",
    "                     log_every_n_steps=1,\n",
    "                     max_steps=5000,\n",
    "                     logger=False,\n",
    "                     checkpoint_callback=False\n",
    "                     )\n",
    "\n",
    "    trainer.fit(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zwischenergebnis\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print('Zwischenergebnis')\n",
    "plot_sampler = tp.samplers.PlotSampler(plot_domain=A_x, n_points=600)\n",
    "fig = tp.utils.plot(model,ansatz_func,plot_sampler) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-GPU-9bdc43ab-3c7a-9d92-3ec5-4207d76cdb68/13/0]\n",
      "\n",
      "  | Name             | Type       | Params\n",
      "------------------------------------------------\n",
      "0 | train_conditions | ModuleList | 5.6 K \n",
      "1 | val_conditions   | ModuleList | 0     \n",
      "------------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n",
      "/home/krd2rng/.conda/envs/pytorch-physics/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/krd2rng/.conda/envs/pytorch-physics/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b04f1d47bf047daa3bc25dbc16140c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if True:\n",
    "    # zu LBFGS wechseln. \n",
    "    # hier LBFGS setzen\n",
    "    optim = tp.OptimizerSetting(optimizer_class=torch.optim.LBFGS, lr=0.5, \n",
    "                                optimizer_args={'max_iter': 4, 'history_size': 100})\n",
    "    pde_condition.sampler = pde_condition.sampler.make_static()   \n",
    "    pos_condition.sampler = pos_condition.sampler.make_static()\n",
    "    solver = tp.solver.Solver([pde_condition, pos_condition],optimizer_setting = optim)\n",
    "\n",
    "    trainer = pl.Trainer(gpus='-1' if torch.cuda.is_available() else None,\n",
    "                     num_sanity_val_steps=0,\n",
    "                     benchmark=True,\n",
    "                     log_every_n_steps=1,\n",
    "                     max_steps=1000,\n",
    "                     logger=False,\n",
    "                     checkpoint_callback=False\n",
    "                     )\n",
    "\n",
    "    trainer.fit(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tp.utils.plot(model,ansatz_func,plot_sampler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14b8952eaac0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.genfromtxt('Referenzloesung_starr.CSV', delimiter=',')[1:, :]\n",
    "plot_sampler = tp.samplers.PlotSampler(plot_domain=A_x, n_points=600, device='cpu')\n",
    "fig = tp.utils.plot(model, ansatz_func, plot_sampler) \n",
    "plt.plot(data[:, 0]/a,data[:, 1]/pskal)\n",
    "plt.legend(['Neural Network', 'Data'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(1.1799, requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_fn.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb770cb910411e790a99fd848f827dc995ac53be5098d939fbaa56bcec3c9277"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-pytorch-physics]",
   "language": "python",
   "name": "conda-env-.conda-pytorch-physics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
